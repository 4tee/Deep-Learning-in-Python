# Changing optimization parameters #

It's time to get your hands dirty with optimization. You'll now try optimizing a model at a very low learning rate, a very high learning rate, and a "just right" learning rate. You'll want to look at the results after running this exercise, remembering that a low value for the loss function is good.

For these exercises, we've pre-loaded the predictors and target values from your previous classification models (predicting who would survive on the Titanic). You'll want the optimization to start from scratch every time you change the learning rate, to give a fair comparison of how each learning rate did in your results. So we have created a function `get_new_model()` that creates an unoptimized model to optimize.

## Instructions ##

* Import `SGD` from `keras.optimizers`.
* Create a list of learning rates to try optimizing with called `lr_to_test`. The learning rates in it should be `.000001`, `0.01`, and `1`.
* Using a `for` loop to iterate over `lr_to_test`:
   * Use `the get_new_model()` function to build a new, unoptimized model.
   * Create an optimizer called `my_optimizer` using the `SGD()` constructor with keyword argument `lr=lr`.
   * Compile your model. Set the `optimizer` parameter to be the SGD object you created above, and because this is a classification problem, use `'categorical_crossentropy'` for the `loss` parameter.
   * Fit your model using the `predictors` and `target`.

```python
# Import the SGD optimizer
from keras.optimizers import SGD

# Create list of learning rates: lr_to_test
lr_to_test = [.000001, 0.01, 1]

# Loop over learning rates
for lr in lr_to_test:
    print('\n\nTesting model with learning rate: %f\n'%lr )
    
    # Build new model to test, unaffected by previous models
    model = get_new_model()
    
    # Create SGD optimizer with specified learning rate: my_optimizer
    my_optimizer = SGD(lr=lr)
    
    # Compile the model
    model.compile(optimizer=my_optimizer, loss='categorical_crossentropy')
    
    # Fit the model
    model.fit(predictors, target)
```

```
    Testing model with learning rate: 0.000001
    
    Epoch 1/10
    
 32/891 [>.............................] - ETA: 0s - loss: 3.6053
672/891 [=====================>........] - ETA: 0s - loss: 3.6398
891/891 [==============================] - 0s - loss: 3.6057     
    Epoch 2/10
    
 32/891 [>.............................] - ETA: 0s - loss: 3.5751
704/891 [======================>.......] - ETA: 0s - loss: 3.5046
891/891 [==============================] - 0s - loss: 3.5656     
    Epoch 3/10
    
 32/891 [>.............................] - ETA: 0s - loss: 2.6692
704/891 [======================>.......] - ETA: 0s - loss: 3.5051
891/891 [==============================] - 0s - loss: 3.5255     
    Epoch 4/10
    
 32/891 [>.............................] - ETA: 0s - loss: 3.0058
704/891 [======================>.......] - ETA: 0s - loss: 3.4634
891/891 [==============================] - 0s - loss: 3.4854     
    Epoch 5/10
    
 32/891 [>.............................] - ETA: 0s - loss: 2.5452
704/891 [======================>.......] - ETA: 0s - loss: 3.4019
891/891 [==============================] - 0s - loss: 3.4454     
    Epoch 6/10
    
 32/891 [>.............................] - ETA: 0s - loss: 3.4446
704/891 [======================>.......] - ETA: 0s - loss: 3.4404
891/891 [==============================] - 0s - loss: 3.4056     
    Epoch 7/10
    
 32/891 [>.............................] - ETA: 0s - loss: 4.1073
704/891 [======================>.......] - ETA: 0s - loss: 3.4208
891/891 [==============================] - 0s - loss: 3.3659     
    Epoch 8/10
    
 32/891 [>.............................] - ETA: 0s - loss: 3.0972
704/891 [======================>.......] - ETA: 0s - loss: 3.2714
891/891 [==============================] - 0s - loss: 3.3263     
    Epoch 9/10
    
 32/891 [>.............................] - ETA: 0s - loss: 3.7464
704/891 [======================>.......] - ETA: 0s - loss: 3.2767
891/891 [==============================] - 0s - loss: 3.2867     
    Epoch 10/10
    
 32/891 [>.............................] - ETA: 0s - loss: 3.3862
704/891 [======================>.......] - ETA: 0s - loss: 3.1384
891/891 [==============================] - 0s - loss: 3.2473     
    
    
    Testing model with learning rate: 0.010000
    
    Epoch 1/10
    
 32/891 [>.............................] - ETA: 1s - loss: 1.0910
512/891 [================>.............] - ETA: 0s - loss: 1.9440
891/891 [==============================] - 0s - loss: 1.4089     
    Epoch 2/10
    
 32/891 [>.............................] - ETA: 0s - loss: 2.0938
480/891 [===============>..............] - ETA: 0s - loss: 0.7570
891/891 [==============================] - 0s - loss: 0.7024     
    Epoch 3/10
    
 32/891 [>.............................] - ETA: 0s - loss: 0.5710
512/891 [================>.............] - ETA: 0s - loss: 0.6856
891/891 [==============================] - 0s - loss: 0.6468     
    Epoch 4/10
    
 32/891 [>.............................] - ETA: 0s - loss: 0.6212
640/891 [====================>.........] - ETA: 0s - loss: 0.6384
891/891 [==============================] - 0s - loss: 0.6190     
    Epoch 5/10
    
 32/891 [>.............................] - ETA: 0s - loss: 0.4955
672/891 [=====================>........] - ETA: 0s - loss: 0.6144
891/891 [==============================] - 0s - loss: 0.6179     
    Epoch 6/10
    
 32/891 [>.............................] - ETA: 0s - loss: 0.6675
576/891 [==================>...........] - ETA: 0s - loss: 0.6080
891/891 [==============================] - 0s - loss: 0.5999     
    Epoch 7/10
    
 32/891 [>.............................] - ETA: 0s - loss: 0.6224
384/891 [===========>..................] - ETA: 0s - loss: 0.6043
768/891 [========================>.....] - ETA: 0s - loss: 0.6013
891/891 [==============================] - 0s - loss: 0.5987     
    Epoch 8/10
    
 32/891 [>.............................] - ETA: 0s - loss: 0.6095
416/891 [=============>................] - ETA: 0s - loss: 0.5901
891/891 [==============================] - 0s - loss: 0.6048     
    Epoch 9/10
    
 32/891 [>.............................] - ETA: 0s - loss: 0.6538
416/891 [=============>................] - ETA: 0s - loss: 0.5914
800/891 [=========================>....] - ETA: 0s - loss: 0.5860
891/891 [==============================] - 0s - loss: 0.5912     
    Epoch 10/10
    
 32/891 [>.............................] - ETA: 0s - loss: 0.6359
352/891 [==========>...................] - ETA: 0s - loss: 0.5625
608/891 [===================>..........] - ETA: 0s - loss: 0.5786
891/891 [==============================] - 0s - loss: 0.5840     
    
    
    Testing model with learning rate: 1.000000
    
    Epoch 1/10
    
 32/891 [>.............................] - ETA: 1s - loss: 1.0273
640/891 [====================>.........] - ETA: 0s - loss: 5.6423
891/891 [==============================] - 0s - loss: 5.9885     
    Epoch 2/10
    
 32/891 [>.............................] - ETA: 0s - loss: 4.5332
256/891 [=======>......................] - ETA: 0s - loss: 5.8554
544/891 [=================>............] - ETA: 0s - loss: 6.1628
891/891 [==============================] - 0s - loss: 6.1867     
    Epoch 3/10
    
 32/891 [>.............................] - ETA: 0s - loss: 7.0517
448/891 [==============>...............] - ETA: 0s - loss: 5.8284
832/891 [===========================>..] - ETA: 0s - loss: 6.2380
891/891 [==============================] - 0s - loss: 6.1867     
    Epoch 4/10
    
 32/891 [>.............................] - ETA: 0s - loss: 6.0443
352/891 [==========>...................] - ETA: 0s - loss: 6.1359
672/891 [=====================>........] - ETA: 0s - loss: 6.1162
891/891 [==============================] - 0s - loss: 6.1867     
    Epoch 5/10
    
 32/891 [>.............................] - ETA: 0s - loss: 9.0664
352/891 [==========>...................] - ETA: 0s - loss: 6.5022
640/891 [====================>.........] - ETA: 0s - loss: 5.9939
891/891 [==============================] - 0s - loss: 6.1867     
    Epoch 6/10
    
 32/891 [>.............................] - ETA: 0s - loss: 6.0443
480/891 [===============>..............] - ETA: 0s - loss: 6.2458
891/891 [==============================] - 0s - loss: 6.1867     
    Epoch 7/10
    
 32/891 [>.............................] - ETA: 0s - loss: 5.0369
608/891 [===================>..........] - ETA: 0s - loss: 6.4684
891/891 [==============================] - 0s - loss: 6.1867     
    Epoch 8/10
    
 32/891 [>.............................] - ETA: 0s - loss: 5.0369
544/891 [=================>............] - ETA: 0s - loss: 6.0443
891/891 [==============================] - 0s - loss: 6.1867     
    Epoch 9/10
    
 32/891 [>.............................] - ETA: 0s - loss: 5.5406
512/891 [================>.............] - ETA: 0s - loss: 6.0758
891/891 [==============================] - 0s - loss: 6.1867     
    Epoch 10/10
    
 32/891 [>.............................] - ETA: 0s - loss: 5.5406
640/891 [====================>.........] - ETA: 0s - loss: 6.2458
891/891 [==============================] - 0s - loss: 6.1867
```